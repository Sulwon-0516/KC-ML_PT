{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Resnet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-P0iMBudJpCC"
      },
      "source": [
        "\"(잔업이다)\" 라는 tag를 추가로 조사하거나 공부해야할 부분에 붙여 두었다. 공부하자.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEUUZnLdCWx4"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data as data_utils\n",
        "#습관적으로 import해야하는 torch package들이다."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyAz9nQtSmDM"
      },
      "source": [
        "3번째로 구현한 class. 정의 순서 때문에, 이렇게 역순으로 작성을 한다. 그보다 논문을 읽은지 너무 오래되어서, ResNet의 downsampling부분에 대한 헷갈림이 있는 것 같다. -> 확인해보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFq4oZ9ZQLBC"
      },
      "source": [
        "class IdentityPadding(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride):\n",
        "    super(IdentityPadding,self).__init__()\n",
        "\n",
        "    self.pooling = nn.MaxPool2d(1,stride=stride)\n",
        "    #이게 호출될때는 stride가 2거나 그럴테니, 이건 down sampling을 수행할 것.\n",
        "    self.add_channels = out_channels - in_channels\n",
        "  \n",
        "  def forward(self, x):\n",
        "    out = F.pad(x, (0,0,0,0,0,self.add_channels))\n",
        "    #이거는 feature map의 마지막 축에대해서는 (0,0) padding, 마지막에서 2번째 축에 대해서는 (0,0) padding, 마지막에서 3번째 축에 대해서는 (0,self.add_channels)만큼 padding을 하라는 의미이다.\n",
        "    #최종적으로 x는 channels축에 대해서 out_channels - in_channels만큼 (아마 2배로) padding될 것이고 zero padding으로 처리될 것이다.\n",
        "\n",
        "    #근데 이러면 끝에 0들이 붙는건데 학습이 되나? (잔업이다)\n",
        "\n",
        "    out = self.pooling(out)\n",
        "\n",
        "    return out\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQeWLkj9QL_V"
      },
      "source": [
        "2번째로 구현한 class. 정의 순서 때문에, 이렇게 역순으로 작성을 한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bV0VMyubMoGU"
      },
      "source": [
        "class ResidualBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, stride=1, down_sample = False):\n",
        "    #앞서 ResNet에서 정의한 block에 들어가는 argument들로 초기화가 되는 것임\n",
        "    super(ResidualBlock, self).__init__()\n",
        "    #항상 그렇든 상속받은거라 실행하고\n",
        "    self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "    self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "    self.relu = nn.ReLU(inplace = True)\n",
        "    #이번엔 block의 처음을 구성할 conv1을 정의하고 따라서 bn1을 정의했다. conv1은 downsampling을 해야하니, 위와같이 따로 정의해줘야 한다.\n",
        "    #ResNet이기에 모두 동일한 3x3 filter로 convolution을 취한다.\n",
        "\n",
        "    self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "    #이건 bn1이랑 같아서 정의 안해도 되는데, 그냥 흐름상 정의한 것 같다. 따라하자.\n",
        "    self.stride = stride\n",
        "    #내부 변수에 저장\n",
        "\n",
        "    if down_sample:\n",
        "      self.down_sample = IdentityPadding(in_channels,out_channels, stride)\n",
        "      #만약 down_sample을 해야하는 첫 레이어라면 Identity padding을 가해서 크기를 변경하는 것.\n",
        "      #만약 input argument down_sample이 True면, self.down_sample을 layer에 추가하는 듯.\n",
        "      #이는 Downsample이 일어나는 첫 layer에서 shortcut 구현에 있어 추가해준 것\n",
        "      #논문에선 다양한 방식을 시도해봤었는데, 조사해보자. (잔업이다)\n",
        "    else:\n",
        "      self.down_sample=None\n",
        "\n",
        "  def forward(self,x):\n",
        "    shortcut = x\n",
        "\n",
        "    out = self.conv1(x)\n",
        "    out = self.bn1(out)\n",
        "    out = self.relu(out)\n",
        "    #첫 layer를 정의함.\n",
        "    #첫 호출만 아니면 in_channels == out_channels이기에 그대로 써도 문제가 없음. conv1==conv2로 작동할 것임.\n",
        "\n",
        "    out = self.conv2(out)\n",
        "    out = self.bn2(out)\n",
        "\n",
        "    if self.down_sample is not None:\n",
        "      shortcut = self. down_sample(x)\n",
        "    #처음에 크기가 변하는 layer에 대해서 shortcut 처리해주기.\n",
        "\n",
        "    out += shortcut\n",
        "    #shortcut을 더해준다.\n",
        "    out = self.relu(out)\n",
        "    #이렇게 shortcut을 더하고 relu를 가하는 것은 relu를 먼저가하면 양의 부분만 남아서, shortcut의 의미가 사라지기 때문이라네.\n",
        "\n",
        "    return out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3v3BtG8MU-P"
      },
      "source": [
        "아래는 ResNet을 정의하는 class이다. \n",
        "github.com/dnddnjs/pytorch-cifar10/blob/enas/resnet/의 파일을 참고했다.\n",
        "\n",
        "가장 먼저 작성한 블락이나, 의존성 때문에 위에 추가적으로 코드를 작성했다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djaaI0BbAIVS"
      },
      "source": [
        "class ResNet(nn.Module):\n",
        "  #class 형태의 module은 nn.Module을 항상 상속받아야 한다.\n",
        "  def __init__(self, num_layers, block, num_classes = 10):\n",
        "    super(ResNet, self).__init__()\n",
        "    #nn.Module.__init__()을 실행해 instance를 만들어야함.\n",
        "    #super는 부모 class의 initalizer를 불러와, 그안의 정보를 사용하고 싶을 때 사용하는 것임. \n",
        "    #이렇게 호출하지 않으면, 덮어씌워지기 때문에 문제의 소지가 큼.\n",
        "    self.num_layers = num_layers \n",
        "    #입력 argument를 복사하기.\n",
        "    self.conv1 = nn.Conv2d(in_channels = 3, out_channels=16, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "    #입력 이미지에 대해 3x3 Conv(kernel_size가 3)를 가하는데, in_channels가 3인 이유는 RGB가 들어오기 떄문이다. \n",
        "    #3x32x32가 들어와서 16x32x32의 feature map이 나가게 된다. 즉 3x3x3짜리 filter가 16set 나오는 것.\n",
        "\n",
        "    self.bn1 = nn.BatchNorm2d(16)\n",
        "    #depth 16짜리 batch normalization을 추가.\n",
        "    self.relu=nn.ReLU(inplace=True)\n",
        "    #inplace를 True로 설정하는 것은 input에서 바로 output으로 바꾼다는 뜻인데, 추가적인 output을 allocation하지 않으니 memory 절약이 가능하다.\n",
        "    #다만, 주의해서 사용해야 한다.\n",
        "\n",
        "\n",
        "    self.layers_2n = self.get_layers(block,16,16,stride=1)\n",
        "    #feature map size 32x32x16 인 2n개의 layer를 구현할 것\n",
        "    self.layers_4n = self.get_layers(block,16,32,stride=2)\n",
        "    #feature map size 16x16x32인 2n~4n layer를 구현할 것\n",
        "    self.layers_6n = self.get_layers(block,32,64,stride=2)\n",
        "    #feature map이 8x8x64인 4n~6n layer를 구현할 것\n",
        "\n",
        "    \n",
        "    #여기서부턴 출력 layer이다.\n",
        "\n",
        "    self.avg_pool = nn.AvgPool2d(8,stride = 1)\n",
        "    #마지막에 average pooling을 8x8 featuremap에 대해서 가할 것이다.(kernel size가 8이라 사실상 전체의 average를 구하는 것) -> 논문 확인 필요 (잔업이다)\n",
        "    self.fc_out= nn.Linear(64, num_classes)\n",
        "    # 64depth의 final output을 num_classes로 이어지는 FCL을 만든다.\n",
        "\n",
        "    for m in self.modules():\n",
        "      # 이 class에 있는 module에 대해서, 이들이 해당하는 instance일 경우 초기화를 해주는 역할이다.\n",
        "      if isinstance(m,nn.Conv2d):\n",
        "        nn.init.kaiming_normal_(m.weight, mode = 'fan_out' , nonlinearity='relu')\n",
        "        #He initialization이라고 한다. normal ditribution을 변형한 거 같은데, 자세히는 추가 조사를 해보자 (잔업이다)\n",
        "        #fan_in을 선택하면 foward pass에서 weight var의 크기를 유지하고, fan_out을 선택하면, backward pass에서 크기를 유지한다 하는데, initializer가 어떻게 그런거를 관여하지 (잔업이다)\n",
        "      elif isinstance(m,nn.BatchNorm2d):\n",
        "        nn.init.constant_(m.weight,1)\n",
        "        # 1인 상수로 weight를 초기화\n",
        "        nn.init.constant_(m.bias,0)\n",
        "        # bais는 0으로 초기화\n",
        "  \n",
        "  def get_layers(self, block, in_channels, out_channels, stride):\n",
        "    if stride ==2:\n",
        "      down_sample = True\n",
        "    else:\n",
        "      down_sample = False\n",
        "    #stride에 따라서 출력 크기가 바뀌는데, 그 여부를 down_sample에 저장해둠.\n",
        "\n",
        "    layers_list = nn.ModuleList([block(in_channels, out_channels, stride, down_sample)])\n",
        "    #입력받은 block을 ModuleList에서 찾아 실행한다.\n",
        "    #위에서 정의된 부분을 사용할 것이다.\n",
        "\n",
        "    for _ in range(self.num_layers-1):\n",
        "      #layer의 갯수만큼 만들어야지.\n",
        "      layers_list.append(block(out_channels, out_channels))\n",
        "\n",
        "    return nn.Sequential(*layers_list)\n",
        "    #근데 *이 의미하는게 뭐지? 일단 layer_list라는 block들의 덩어리를 return하겠다는 건 이해가 되는데. (잔업이다)\n",
        "\n",
        "\n",
        "  def forward(self,x):\n",
        "    #forward propagation을 진행하는 부분이다.\n",
        "    #항상 쓰이며, 여기서 Model의 구조를 위에 정의한 Module들을 가지고 하는 것\n",
        "\n",
        "    x = self.conv1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.relu(x)\n",
        "    #첫 입력 신호 차원 바꾸는 conv layer\n",
        "\n",
        "    x=self.layers_2n(x)\n",
        "    x=self.layers_4n(x)\n",
        "    x=self.layers_6n(x)\n",
        "    #Resnet block들을 이어주고\n",
        "\n",
        "    x=self.avg_pool(x)\n",
        "    x=x.view(x.size(0),-1)\n",
        "    x=self.fc_out(x)\n",
        "    #최종 출력 layer를 정의한다.\n",
        "\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S10mYVqtJnq9"
      },
      "source": [
        "최종적으로 아래의 함수로 위의 class들을 호출해 ResNet을 정의한다.\n",
        "\n",
        "최종 레이어는 6n+2개로 구성될 것이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "osW6sS61CVVc"
      },
      "source": [
        "def resnet(n):\n",
        "  block = ResidualBlock\n",
        "\n",
        "  model = ResNet(n,block)\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKVZWz3jTfso"
      },
      "source": [
        "여기까지가 Model의 정의였고, 이제는 training 하는 부분을 만들어야 한다.\n",
        "\n",
        "skeleton code와 위에 구현된 code를 바탕으로 하나씩 옮겨 적으며 정리를 해보았다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lgr8L-0tjbhh",
        "outputId": "9b195df3-e6a5-43fd-a3f9-1fbaa27d0b4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%pip install tensorboardX"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.6/dist-packages (2.1)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.18.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorboardX) (50.3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZI9ob_PTsNK"
      },
      "source": [
        "import os\n",
        "from torch.optim import lr_scheduler\n",
        "#epoch에 따라서 learning rate를 조절해주는 함수이다.\n",
        "import torch.backends.cudnn as cudnn\n",
        "\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torch.utils.data import DataLoader\n",
        "#학습에 쓸 CIFAR10데이터 셋과 preprocess를 위한 transform 패키지를 얻는다.\n",
        "\n",
        "import argparse\n",
        "# 이건 파일 실행시 인자값을 받는 용도로 정의되는 것임 (잔업이다)\n",
        "from tensorboardX import SummaryWriter\n",
        "#좋은 visualizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C9zXhRAhVwd6"
      },
      "source": [
        "이 부분은 parser로 python이 호출되어서 작동할떄, 요구받는 인자이다. \n",
        "Python에서만 적용되는 거라 처음보고 익숙하지가 않다... ㅠ\n",
        "\n",
        "(잔업이다)\n",
        "\n",
        "\n",
        "notebook에서 구현하다 보니, 작동에 문제가 있는 것 같다. \n",
        "일단은 주석처리 해두자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QCfh2cx7Uodz"
      },
      "source": [
        "'''\n",
        "\n",
        "parser = argparse.ArgumentParser(description='cifar10 classification models')\n",
        "#인자값을 받는 instance를 형성한다.\n",
        "\n",
        "parser.add_argument('--lr',default=0.1, help='')\n",
        "parser.add_argument('--resume',default= None, help='')\n",
        "parser.add_argument('--batch_size',default = 128, help='')\n",
        "parser.add_argument('--batch_size_test',default = 100, help='')\n",
        "parser.add_argument('--num_worker',default=4,help='')\n",
        "parser.add_argument('--logdir',type = str, default='logs',help='')\n",
        "#인자값들을 입력받는 설정을 보여준다.\n",
        "#원래 trainer 초반에 정의해두는 hyperparameter들을 여기의 default로 설정을 함으로 정의하고 있다.\n",
        "\n",
        "args = parser.parse_args()\n",
        "#입력받은 인자값을 args에다가 저장한다.\n",
        "'''\n",
        "class Arg:\n",
        "  def __init__(self):\n",
        "    self.lr = 0.1\n",
        "    self.resume = None\n",
        "    self.batch_size = 128\n",
        "    self.batch_size_test = 100\n",
        "    self.num_worker = 4\n",
        "    self.logdir = 'logs'\n",
        "\n",
        "args = Arg()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hMX8Uo_XSlQ"
      },
      "source": [
        "이 부분은 데이터를 받아오고, preprocessing을 가하는 부분이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_pYUFicZrno",
        "outputId": "e5c6980f-61ee-4758-ed93-6357c889db32",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%mkdir ./data\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘./data’: File exists\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzweBxmWXCl1",
        "outputId": "3b0a731e-09e9-4168-e3fe-117654996125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "#CUDA가 사용 가능하면 cuda를 쓰고, 그게 아니면 cpu를 사용하자.\n",
        "\n",
        "print('preprocessing data')\n",
        "\n",
        "transforms_train = transforms.Compose(\n",
        "    [\n",
        "     transforms.RandomCrop(32,padding=4),\n",
        "     #32x32로 padding 4까지 허용하고 Random Crop\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     #Random하게 Flip\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),\n",
        "     #이건 CIFAR10의 channel별 평균관 std-deviation이다.\n",
        "     #이거로 standardization을 하는 것\n",
        "    ]\n",
        ")\n",
        "transforms_test = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.4914,0.4822,0.4465),(0.2023,0.1994,0.2010)),\n",
        "    ]\n",
        ")\n",
        "#전처리 + 데이터 늘리기를 수행하는 함수? instance?를 정의\n",
        "\n",
        "dataset_train = CIFAR10(root='./data', train=True, download=True, transform=transforms_train)\n",
        "dataset_test = CIFAR10(root='./data',train=False ,download=True,transform= transforms_test)\n",
        "#./data에 CIFAR10을 다운로드 한다\n",
        "\n",
        "train_loader = DataLoader(dataset_train, batch_size=args.batch_size, shuffle = True, num_workers = args.num_worker)\n",
        "test_loader = DataLoader(dataset_test,batch_size=args.batch_size_test, shuffle = False, num_workers= args.num_worker)\n",
        "#DataLoader로 파일들을 불러온다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "preprocessing data\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXZBJ0_YbaZb"
      },
      "source": [
        "이제는 Model과 세부 사항을 조절할 차례"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xDdlec0ebefO",
        "outputId": "22782c3e-05e6-4717-ffbd-d5f9d5c29f3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print('Making model')\n",
        "\n",
        "net = resnet(5)\n",
        "net = net.to(device)\n",
        "#설정한 device에서 작동하게 설정\n",
        "\n",
        "num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n",
        "# 총 parameter의 갯수를 구한다.\n",
        "# net이 nn.Module을 상속했기에, parameters()나 parameters.requires_grad 같은게 작동함\n",
        "print('The number of parameters of model is', num_params)\n",
        "print(net)\n",
        "\n",
        "if args.resume is not None:\n",
        "  checkpoint = torch.load('./save_model'+args.resume)\n",
        "  net.load_state_dict(checkpoint['net'])\n",
        "#만약 resume하는 경우엔, ./save_model에서 불러와 net에다가 집어 넣는 역할이다.\n",
        "\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr= args.lr, momentum = 0.9, weight_decay = 1e-4)\n",
        "#cross entropy를 loss로 사용하고, SGD를 optimizer로 설정했다\n",
        "#Momentum은 0.9, weight_decay는 0.0001로 설정헀는데, 이거 앞에 상수로 빼주면 훨씬 좋을것 같다고 생각함.\n",
        "\n",
        "decay_epoch = [32000,48000]\n",
        "step_lr_scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=decay_epoch, gamma = 0.1)\n",
        "#이거는 Learning rate decay를 표현하는 식이다.\n",
        "#gamma가 0.1이니 한번 decay 될때마다 0.1씩 되는 것이고, 32000epoch에서 한번, 48000epoch에서 한번 작동한다.\n",
        "\n",
        "writer = SummaryWriter(args.logdir)\n",
        "#요약 작성 (자동으론 logs란 파일에 작성될 것)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Making model\n",
            "The number of parameters of model is 464154\n",
            "ResNet(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (layers_2n): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): ResidualBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): ResidualBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layers_4n): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down_sample): IdentityPadding(\n",
            "        (pooling): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): ResidualBlock(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): ResidualBlock(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layers_6n): Sequential(\n",
            "    (0): ResidualBlock(\n",
            "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (down_sample): IdentityPadding(\n",
            "        (pooling): MaxPool2d(kernel_size=1, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      )\n",
            "    )\n",
            "    (1): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): ResidualBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avg_pool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
            "  (fc_out): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvPKnpymdtTn"
      },
      "source": [
        "대망의 Training 함수이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DgIvC_pbdsU9"
      },
      "source": [
        "def train(epoch, global_steps):\n",
        "  net.train()\n",
        "\n",
        "  train_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "    #enumerate는 iterator임. \n",
        "    #앞서 train_loader를 정의할때 넣어준 batch_size만큼 for 문이 도는 것\n",
        "    global_steps +=1\n",
        "    step_lr_scheduler.step()\n",
        "    #이 친구는 독립적을 움직이니 이렇게 추가해줘야해.\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    outputs = net(inputs)\n",
        "    loss = criterion(outputs, targets)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    #역전파를 계산전에 변화도를 0으로 설정.\n",
        "    #backward가 grad를 계산하게 되는데, autograd랑 충돌하니까 끈다는 느낌 (잔업이다)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    #back propagation을 계산.\n",
        "\n",
        "    train_loss += loss.item()\n",
        "    _, predicted = outputs.max(1)\n",
        "    #top 1 predict를 얻음\n",
        "    total += targets.size(0)\n",
        "    correct += predicted.eq(targets).sum().item()\n",
        "    #predict랑 target이 같으면 correct를 올림. total을 그냥 올림.\n",
        "\n",
        "  acc = 100 * correct/ total\n",
        "  #정확도를 정의.\n",
        "  print('train epoch : {} [{}/{}] | loss : {:.3f} | acc : {:.3f}'.format(epoch,batch_idx,len(train_loader), train_loss/(batch_idx+1),acc))\n",
        "  #epoch마다 결과를 출력하는 것.\n",
        "\n",
        "  writer.add_scalar('log/train error', 100-acc, global_steps)\n",
        "\n",
        "  return global_steps\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y5i5NQE6ft05"
      },
      "source": [
        "테스트 함수임."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAQVS2uofrg9"
      },
      "source": [
        "def test(epoch, best_acc, global_steps):\n",
        "  net.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    #여기서 하는 일은 history tracking을 안하겠다는 것.\n",
        "    #testing이니까 속도를 높여주려 그런게 아닐까?\n",
        "    for batch_idx, (inputs, targets) in enumerate(test_loader):\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "      outputs = net(inputs)\n",
        "      loss = criterion(outputs, targets)\n",
        "\n",
        "      test_loss += loss.item()\n",
        "      _, predicted = outputs.max(1)\n",
        "      total+= targets.size(0)\n",
        "      correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "  acc = 100 * correct / total\n",
        "  print('test epoch : {} [{}/{}] | loss : {:.3f} | acc : {:.3f}'.format(epoch,batch_idx,len(test_loader), test_loss/(batch_idx+1),acc))\n",
        "\n",
        "  writer.add_scalar('log/train error', 100-acc, global_steps)\n",
        "  #위의 train에서 backward()만 뺀거라 설명할게 크게 없다.\n",
        "\n",
        "\n",
        "  if acc > best_acc:\n",
        "    print('Saving model')\n",
        "    state = {'net':net.state_dict(),'acc':acc, 'epoch':epoch,}\n",
        "    \n",
        "    if not os.path.isdir('save_model'):\n",
        "      #저장 폴더가 없으면 만들기\n",
        "      os.mkdir('save_model')\n",
        "    torch.save(state,'./save_model/ckpt.pth')\n",
        "    best_acc = acc\n",
        "  #최고 기록인 모델 저장하기\n",
        "\n",
        "  return best_acc\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK4ATSjfigTQ"
      },
      "source": [
        "드디어 대망의 main함수. 근데 뭐 그러듯 별 볼거 없다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMuIq7TGijjJ",
        "outputId": "026cac1c-5f0d-4a03-f1b0-ab31252bd65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        }
      },
      "source": [
        "if __name__=='__main__':\n",
        "\n",
        "  best_acc = 0\n",
        "  epoch = 0\n",
        "  global_steps = 0\n",
        "\n",
        "  if args.resume is not None:\n",
        "    #저장된게 있었으면, 그 모델로 test를 한다. (추가적인 train을 하진 않게 설정했네)\n",
        "    test(epoch = 0, best_acc = 0)\n",
        "  else:\n",
        "    while True:\n",
        "      epoch +=1\n",
        "      global_steps = train(epoch, global_steps)\n",
        "      best_acc = test(epoch, best_acc, global_steps)\n",
        "      print('best test accuracy is ', best_acc)\n",
        "\n",
        "      if global_steps >= 64000:\n",
        "        #탈출조건\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-566456f0186a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m       \u001b[0mglobal_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m       \u001b[0mbest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m       \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best test accuracy is '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-6d4b66e6ef45>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch, global_steps)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#back propagation을 계산.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;31m#top 1 predict를 얻음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}